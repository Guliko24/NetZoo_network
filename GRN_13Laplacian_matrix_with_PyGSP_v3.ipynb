{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPxbNRgTEXQd1bIBYlMVDe7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Guliko24/NetZoo_network/blob/main/GRN_13Laplacian_matrix_with_PyGSP_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# This is a block of code working with single files from MCF7 and MDA-MB-231 cell lines\n",
        "\n"
      ],
      "metadata": {
        "id": "b2rWRHpeusKj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import all the packages as needed\n",
        "import pandas as pd\n",
        "import networkx as nx"
      ],
      "metadata": {
        "id": "gggoURRVt2pF"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "21fqZLYLvFFU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "wvgjdb8enMPL",
        "outputId": "7d4849d9-3b90-45b3-ef04-0b8b0a94a212"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-283a36a98ef5>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    135\u001b[0m   )\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# prompt: let's load Gdrive onto notebook\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Navigate to your Google Drive files\n",
        "%cd /content/drive/MyDrive/Essex_MSc_AI_24-25/MSc_Project_24/Data_to_work_with/GRAND_datasets\n"
      ],
      "metadata": {
        "id": "-QugfNefrPUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#let's read the MCF7_TF_Genes dataset and make changes\n",
        "df_MCF7_TF_Genes = pd.read_csv('/content/drive/MyDrive/Essex_MSc_AI_24-25/MSc_Project_24/Data_to_work_with/GRAND_datasets/MCF7_raw/ACH-000019_TF_vs_Genes_total expression.csv', index_col=0)"
      ],
      "metadata": {
        "id": "WEeiEejRMA3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#let's do initial data assessment\n",
        "#df_MCF7_TF_Genes.head()\n"
      ],
      "metadata": {
        "id": "_tMAlOZ3Mwn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df_MCF7_TF_Genes.info()\n"
      ],
      "metadata": {
        "id": "l4yuBt0cPAP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(df_MCF7_TF_Genes.describe())"
      ],
      "metadata": {
        "id": "j12uNgUSP_5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(df_MCF7_TF_Genes.isnull().sum())"
      ],
      "metadata": {
        "id": "ZP49BI3nSXfc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#plt.figure(figsize=(10, 8))\n",
        "#sns.heatmap(df_MCF7_TF_Genes.iloc[:, 1:], cmap='viridis')  # Skipping the first column if it's TF names\n",
        "#plt.title('Heatmap of Gene Expression by TF')\n",
        "#plt.show()\n"
      ],
      "metadata": {
        "id": "OLwU1gR3Svyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5FUp1j4jb7T5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def normalize_matrix(matrix: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Normalize the values in the matrix to a range of [0, 1].\n",
        "    \"\"\"\n",
        "    normalized_matrix = (matrix - matrix.min().min()) / (matrix.max().max() - matrix.min().min())\n",
        "    return normalized_matrix\n",
        "\n",
        "def filter_by_threshold(matrix: pd.DataFrame, threshold: float, mode: str = 'greater') -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Filter the matrix based on a threshold.\n",
        "    Parameters:\n",
        "        matrix: The TF vs Genes interaction matrix.\n",
        "        threshold: The threshold value for filtering.\n",
        "        mode: 'greater' to keep values greater than threshold, 'less' to keep values less than threshold.\n",
        "    \"\"\"\n",
        "    if mode == 'greater':\n",
        "        return matrix[matrix > threshold].fillna(0)\n",
        "    elif mode == 'less':\n",
        "        return matrix[matrix < threshold].fillna(0)\n",
        "    else:\n",
        "        raise ValueError(\"Mode must be either 'greater' or 'less'\")\n",
        "\n",
        "def binarize_matrix(matrix: pd.DataFrame, threshold: float) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Binarize the matrix based on a threshold.\n",
        "    Values greater than or equal to the threshold become 1, otherwise 0.\n",
        "    \"\"\"\n",
        "    binary_matrix = (matrix >= threshold).astype(int)\n",
        "    return binary_matrix\n",
        "\n",
        "def rank_interactions(matrix: pd.DataFrame, top_n: int = 5) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Rank the top N interactions for each transcription factor.\n",
        "    Parameters:\n",
        "        matrix: The TF vs Genes interaction matrix.\n",
        "        top_n: Number of top interactions to return for each TF.\n",
        "    \"\"\"\n",
        "    ranked_interactions = pd.DataFrame()\n",
        "    for tf in matrix.index:\n",
        "        top_genes = matrix.loc[tf].nlargest(top_n)\n",
        "        ranked_interactions = pd.concat([ranked_interactions, top_genes], axis=1)\n",
        "    return ranked_interactions.T\n",
        "\n",
        "def aggregate_interactions(matrix: pd.DataFrame, axis: int = 0) -> pd.Series:\n",
        "    \"\"\"\n",
        "    Aggregate interaction strengths.\n",
        "    Parameters:\n",
        "        axis: 0 to aggregate across genes (per TF), 1 to aggregate across TFs (per Gene).\n",
        "    \"\"\"\n",
        "    return matrix.sum(axis=axis)\n",
        "\n",
        "def construct_interaction_network(matrix: pd.DataFrame, threshold: float) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Construct an interaction network by keeping only interactions above a threshold.\n",
        "    Returns a DataFrame representing edges in the network.\n",
        "    \"\"\"\n",
        "    filtered_matrix = filter_by_threshold(matrix, threshold, mode='greater')\n",
        "    edges = []\n",
        "    for tf in filtered_matrix.index:\n",
        "        for gene in filtered_matrix.columns:\n",
        "            if filtered_matrix.loc[tf, gene] > 0:\n",
        "                edges.append((tf, gene, filtered_matrix.loc[tf, gene]))\n",
        "    network_df = pd.DataFrame(edges, columns=['TF', 'Gene', 'Interaction_Strength'])\n",
        "    return network_df\n",
        "\n",
        "def split_positive_negative_matrices(matrix: pd.DataFrame) -> (pd.DataFrame, pd.DataFrame):\n",
        "    \"\"\"\n",
        "    Split the matrix into two DataFrames: one for positive values and one for negative values.\n",
        "    Ensure that the matrix values are numeric by coercing errors and replacing non-numeric values with NaN.\n",
        "    Retain the index and columns in both matrices.\n",
        "    \"\"\"\n",
        "    matrix_numeric = matrix.apply(pd.to_numeric, errors='coerce')\n",
        "    positive_matrix = matrix_numeric.where(matrix_numeric > 0).fillna(0)\n",
        "    negative_matrix = matrix_numeric.where(matrix_numeric < 0).fillna(0)\n",
        "    positive_matrix.index = matrix.index\n",
        "    positive_matrix.columns = matrix.columns\n",
        "    negative_matrix.index = matrix.index\n",
        "    negative_matrix.columns = matrix.columns\n",
        "    return positive_matrix, negative_matrix\n",
        "\n",
        "def check_repeated_indices_columns(matrix: pd.DataFrame):\n",
        "    \"\"\"\n",
        "    Check for repeated transcription factors (rows) and genes (columns) in the matrix.\n",
        "    \"\"\"\n",
        "    repeated_rows = matrix.index[matrix.index.duplicated()].unique()\n",
        "    repeated_columns = matrix.columns[matrix.columns.duplicated()].unique()\n",
        "\n",
        "    print(\"Repeated Rows (TFs):\")\n",
        "    if len(repeated_rows) > 0:\n",
        "        print(repeated_rows)\n",
        "    else:\n",
        "        print(\"No repeated rows found.\")\n",
        "\n",
        "    print(\"\\nRepeated Columns (Genes):\")\n",
        "    if len(repeated_columns) > 0:\n",
        "        print(repeated_columns)\n",
        "    else:\n",
        "        print(\"No repeated columns found.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "d_1lbOcqMfYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example Usage\n",
        "# Read the TF vs Genes matrix from a CSV file\n",
        "#df_MCF7_TF_Genes = pd.read_csv('/content/drive/MyDrive/Essex_MSc_AI_24-25/MSc_Project_24/Data_to_work_with/GRAND_datasets/MCF7_raw/ACH-000019_TF_vs_Genes_total expression.csv', index_col=0)\n",
        "\n",
        "# Normalize the matrix\n",
        "#normalized_df = normalize_matrix(df_MCF7_TF_Genes)\n",
        "\n",
        "# Filter interactions greater than 0.5\n",
        "#filtered_df = filter_by_threshold(df_MCF7_TF_Genes, threshold=0.5, mode='greater')\n",
        "\n",
        "# Binarize the matrix with a threshold of 0.5\n",
        "#binary_df = binarize_matrix(df_MCF7_TF_Genes, threshold=0.5)\n",
        "\n",
        "# Rank top 2 interactions for each TF\n",
        "#ranked_df = rank_interactions(df_MCF7_TF_Genes, top_n=2)\n",
        "\n",
        "# Aggregate interactions across genes (per TF)\n",
        "#aggregated_series = aggregate_interactions(df_MCF7_TF_Genes, axis=1)\n",
        "\n",
        "# Construct interaction network with a threshold of 0.5\n",
        "#network_df = construct_interaction_network(df_MCF7_TF_Genes, threshold=0.5)\n",
        "\n",
        "# Split the matrix into positive and negative interaction matrices\n",
        "positive_df, negative_df = split_positive_negative_matrices(df_MCF7_TF_Genes)"
      ],
      "metadata": {
        "id": "6v-hqZv7PI5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positive_df.head()"
      ],
      "metadata": {
        "id": "bqwKKjlAQI87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "negative_df"
      ],
      "metadata": {
        "id": "fAsruqaHQN8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check each dataframes (positive and negative) for:\n",
        "\n",
        "1) distribution of values:\n",
        "\n",
        "  remove zero interactions\n",
        "  may be create subnodes where there are more genes per TF\n",
        "  may be create subnodes where there are more TFs per gene\n",
        "\n",
        "2) non-zero interactions\n",
        "\n",
        "3) visualization\n"
      ],
      "metadata": {
        "id": "M8UoOhYySJK6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check summary statistics for positive and negative matrices\n",
        "print(\"Positive Matrix Summary:\")\n",
        "print(positive_df.describe())\n",
        "print(\"\\nNegative Matrix Summary:\")\n",
        "print(negative_df.describe())\n",
        "\n",
        "# Count non-zero interactions in positive and negative matrices\n",
        "positive_nonzero_count = (positive_df > 0).sum().sum()\n",
        "negative_nonzero_count = (negative_df < 0).sum().sum()\n",
        "\n",
        "print(f\"\\nNumber of non-zero interactions in Positive Matrix: {positive_nonzero_count}\")\n",
        "print(f\"Number of non-zero interactions in Negative Matrix: {negative_nonzero_count}\")\n",
        "\n",
        "# Visualize the matrices using heatmaps\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Positive Matrix Heatmap\n",
        "#plt.figure(figsize=(10, 6))\n",
        "#sns.heatmap(positive_df, cmap=\"YlGnBu\", cbar=True)\n",
        "#plt.title(\"Positive Interactions Heatmap\")\n",
        "#plt.show()\n",
        "\n",
        "# Negative Matrix Heatmap\n",
        "#plt.figure(figsize=(10, 6))\n",
        "#sns.heatmap(negative_df, cmap=\"coolwarm\", cbar=True)\n",
        "#plt.title(\"Negative Interactions Heatmap\")\n",
        "#plt.show()\n"
      ],
      "metadata": {
        "id": "v9joxTENQ93C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#lets check whether there is a repetition of rows or columns\n",
        "# Check for repeated rows (TFs) and columns (Genes)\n",
        "check_repeated_indices_columns(positive_df)\n",
        "check_repeated_indices_columns(negative_df)"
      ],
      "metadata": {
        "id": "RnILvGFVg-N3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten the dataframe into a series with TF-Gene pair as the index\n",
        "ranked_positive_df = positive_df.stack().sort_values(ascending=False)\n",
        "\n",
        "# Get the top 200 interactions\n",
        "top_300_positive_df = ranked_positive_df.head(300)\n",
        "print(top_300_positive_df)\n"
      ],
      "metadata": {
        "id": "FQtBZMFU_4Dm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten the dataframe into a series with TF-Gene pair as the index\n",
        "ranked_negative_df = negative_df.stack().sort_values(ascending=True)\n",
        "\n",
        "# Get the top 200 interactions\n",
        "top_300_negative_df = ranked_negative_df.head(300)\n",
        "print(top_300_negative_df)\n"
      ],
      "metadata": {
        "id": "yqy1Y0OKAejl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename the columns of the positive and negative dataframes\n",
        "top_300_positive_df = top_300_positive_df.reset_index()\n",
        "top_300_positive_df.columns = [\"Source\", \"Target\", \"Edge weight\"]\n",
        "\n",
        "top_300_negative_df = top_300_negative_df.reset_index()\n",
        "top_300_negative_df.columns = [\"Source\", \"Target\", \"Edge weight\"]\n",
        "\n",
        "# Display the updated dataframes\n",
        "print(\"Top 300 Positive Interactions:\")\n",
        "print(top_300_positive_df.head())\n",
        "\n",
        "print(\"\\nTop 300 Negative Interactions:\")\n",
        "print(top_300_negative_df.head())\n"
      ],
      "metadata": {
        "id": "7mUQHd-PVXaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "import pandas as pd\n",
        "from networkx.algorithms import community\n",
        "\n",
        "\n",
        "\n",
        "# Initialize directed graph for positive interactions\n",
        "G_positive = nx.DiGraph()\n",
        "\n",
        "# Add edges from the dataframe to the directed graph\n",
        "for _, row in top_300_positive_df.iterrows():\n",
        "    G_positive.add_edge(row['Source'], row['Target'], weight=row['Edge weight'])\n",
        "\n",
        "# Set a layout for the graph\n",
        "pos = nx.spring_layout(G_positive, k=0.8, iterations=100)\n",
        "\n",
        "# Separate nodes based on Source and Target\n",
        "source_nodes = set(top_300_positive_df['Source'])\n",
        "target_nodes = set(top_300_positive_df['Target'])\n",
        "\n",
        "# Draw the main graph\n",
        "plt.figure(figsize=(12, 10))\n",
        "nx.draw(\n",
        "    G_positive, pos, with_labels=True, node_size=200, nodelist=source_nodes,\n",
        "    node_color=\"pink\", alpha=0.7, font_size=8, edge_color=\"darkgrey\"\n",
        ")\n",
        "nx.draw(\n",
        "    G_positive, pos, with_labels=True, node_size=200, nodelist=target_nodes,\n",
        "    node_color=\"blue\", alpha=0.6, font_size=8, edge_color=\"darkgrey\"\n",
        ")\n",
        "plt.title(\"Main Graph with TFs (Pink) and Genes (Blue)\")\n",
        "plt.show()\n",
        "\n",
        "# Calculate communities\n",
        "communities = community.greedy_modularity_communities(G_positive)\n",
        "# Create subplots for communities\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 7))\n",
        "\n",
        "for idx, comm in enumerate(communities[:2]):  # First two communities\n",
        "    subgraph = G_positive.subgraph(comm)\n",
        "    sub_pos = nx.spring_layout(subgraph, k=0.8)  # Separate layout for each community\n",
        "\n",
        "    # Separate nodes into TFs and genes for this subgraph\n",
        "    sub_source_nodes = [node for node in comm if node in source_nodes]\n",
        "    sub_target_nodes = [node for node in comm if node in target_nodes]\n",
        "\n",
        "    # Draw source nodes (TFs) in pink\n",
        "    nx.draw(\n",
        "        subgraph, sub_pos, ax=axes[idx], with_labels=True, node_size=200,\n",
        "        nodelist=sub_source_nodes, node_color=\"pink\", alpha=0.7, font_size=8\n",
        "    )\n",
        "\n",
        "    # Draw target nodes (genes) in blue\n",
        "    nx.draw(\n",
        "        subgraph, sub_pos, ax=axes[idx], with_labels=True, node_size=200,\n",
        "        nodelist=sub_target_nodes, node_color=\"blue\", alpha=0.6, font_size=8\n",
        "    )\n",
        "\n",
        "    axes[idx].set_title(f\"Community {idx + 1}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "5tOb1QD0OrUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZVc-JxH4Hu32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Initialize directed graph for positive interactions\n",
        "G_negative = nx.DiGraph()\n",
        "\n",
        "# Add edges from the dataframe to the directed graph\n",
        "for _, row in top_300_negative_df.iterrows():\n",
        "    G_negative.add_edge(row['Source'], row['Target'], weight=row['Edge weight'])\n",
        "\n",
        "# Set a layout for the graph\n",
        "pos = nx.spring_layout(G_negative, k=0.6, iterations=30)\n",
        "\n",
        "# Separate nodes based on Source and Target\n",
        "source_nodes = set(top_300_negative_df['Source'])\n",
        "target_nodes = set(top_300_negative_df['Target'])\n",
        "\n",
        "# Draw the source nodes in pink\n",
        "nx.draw(G_negative, pos, with_labels=True, node_size=1000, nodelist=source_nodes, node_color=\"orange\", font_size=8, edge_color='darkgrey')\n",
        "\n",
        "# Draw the target nodes in blue, without overriding the previously drawn source nodes\n",
        "nx.draw(G_negative, pos, with_labels=True, node_size=1000, nodelist=target_nodes, node_color=\"green\", alpha=0.6, font_size=8, edge_color='darkgrey')\n",
        "\n",
        "# Draw edge labels to show weights with smaller font size\n",
        "#edge_labels = nx.get_edge_attributes(G_negative, 'weight')\n",
        "#nx.draw_networkx_edge_labels(G_negative, pos, edge_labels=edge_labels, font_size=8)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "2pBO2CeBHvQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "import pandas as pd\n",
        "from networkx.algorithms import community\n",
        "\n",
        "# Initialize directed graph for negative interactions\n",
        "G_negative = nx.DiGraph()\n",
        "\n",
        "# Add edges from the dataframe to the directed graph\n",
        "for _, row in top_300_negative_df.iterrows():\n",
        "    G_negative.add_edge(row['Source'], row['Target'], weight=row['Edge weight'])\n",
        "\n",
        "# Set a layout for the graph\n",
        "pos = nx.spring_layout(G_negative, k=0.6, iterations=30)\n",
        "\n",
        "# Separate nodes based on Source and Target\n",
        "source_nodes = set(top_300_negative_df['Source'])\n",
        "target_nodes = set(top_300_negative_df['Target'])\n",
        "\n",
        "# Draw the main graph\n",
        "plt.figure(figsize=(10, 8))\n",
        "nx.draw(\n",
        "    G_negative, pos, with_labels=True, node_size=1000, nodelist=source_nodes,\n",
        "    node_color=\"orange\", alpha=0.7, font_size=8, edge_color=\"darkgrey\"\n",
        ")\n",
        "nx.draw(\n",
        "    G_negative, pos, with_labels=True, node_size=1000, nodelist=target_nodes,\n",
        "    node_color=\"green\", alpha=0.6, font_size=8, edge_color=\"darkgrey\"\n",
        ")\n",
        "plt.title(\"Main Graph with TFs (Orange) and Genes (Green)\")\n",
        "plt.show()\n",
        "\n",
        "# Calculate communities for the negative graph\n",
        "communities_negative = community.greedy_modularity_communities(G_negative)\n",
        "\n",
        "# Create subplots for communities\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 7))\n",
        "\n",
        "for idx, comm in enumerate(communities_negative[:2]):  # First two communities\n",
        "    subgraph = G_negative.subgraph(comm)\n",
        "    sub_pos = nx.spring_layout(subgraph, k=0.8)  # Separate layout for each community\n",
        "\n",
        "    # Separate nodes into TFs and genes for this subgraph\n",
        "    sub_source_nodes = [node for node in comm if node in source_nodes]\n",
        "    sub_target_nodes = [node for node in comm if node in target_nodes]\n",
        "\n",
        "    # Draw source nodes (TFs) in orange\n",
        "    nx.draw(\n",
        "        subgraph, sub_pos, ax=axes[idx], with_labels=True, node_size=1000,\n",
        "        nodelist=sub_source_nodes, node_color=\"orange\", alpha=0.7, font_size=8\n",
        "    )\n",
        "\n",
        "    # Draw target nodes (genes) in green\n",
        "    nx.draw(\n",
        "        subgraph, sub_pos, ax=axes[idx], with_labels=True, node_size=1000,\n",
        "        nodelist=sub_target_nodes, node_color=\"green\", alpha=0.6, font_size=8\n",
        "    )\n",
        "\n",
        "    axes[idx].set_title(f\"Community {idx + 1}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "aISIBbjVP8gq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have attempted using Kamada and Planar layouts and it did not yield any explainable or reasonable plots"
      ],
      "metadata": {
        "id": "eD5qgEHeiaQc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Save the graph in formats like GraphML or GEXF for visualization in tools like Gephi.\n",
        "nx.write_graphml(G_positive, \"positive_interactions.graphml\")\n",
        "nx.write_graphml(G_negative, \"negative_interactions.graphml\")"
      ],
      "metadata": {
        "id": "8OfyDndKWLBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "KIccc7VzWEXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let's install PyGPS (suggested by Ortega) and use it for signal processing:"
      ],
      "metadata": {
        "id": "gIYvte8vZL39"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pygsp\n"
      ],
      "metadata": {
        "id": "OOeMRp5EZVKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Convert NetworkX Graph to PyGSP Graph**"
      ],
      "metadata": {
        "id": "mHsBdtpnix_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#I decided to use PyGSP package so few adjustments will be required\n",
        "import networkx as nx\n",
        "import pygsp as pg\n",
        "from networkx import to_scipy_sparse_array\n",
        "\n",
        "# Extract adjacency matrix from NetworkX graph\n",
        "# Extract adjacency matrix from NetworkX graph as a sparse array\n",
        "G_positive.remove_edges_from(nx.selfloop_edges(G_positive))##### remove the loop here so now I have 299 edges\n",
        "adjacency_matrix_pos = to_scipy_sparse_array(G_positive, weight=\" Edge weight\")\n",
        "\n",
        "# Create PyGSP graph\n",
        "gsp_graph_pos= pg.graphs.Graph(adjacency_matrix_pos)\n",
        "\n",
        "# Display basic graph info\n",
        "print(f\"PyGSP Graph Positive with {gsp_graph_pos.N} nodes and {gsp_graph_pos.Ne} edges.\")\n"
      ],
      "metadata": {
        "id": "pH1eqnZpaHmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5RjCzHHEfHS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract adjacency matrix from NetworkX graph for Negative graph\n",
        "# Extract adjacency matrix from NetworkX graph as a sparse array\n",
        "adjacency_matrix_neg = to_scipy_sparse_array(G_negative, weight=\" Edge weight\")\n",
        "\n",
        "# Create PyGSP graph\n",
        "gsp_graph_neg= pg.graphs.Graph(adjacency_matrix_neg)\n",
        "\n",
        "# Display basic graph info\n",
        "print(f\"PyGSP Graph Negative with {gsp_graph_neg.N} nodes and {gsp_graph_neg.Ne} edges.\")\n"
      ],
      "metadata": {
        "id": "5UAU4SwQfHsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "since our positive graph has loops, i.e. gene strongly interacting with itself (may be acts as a dimer?), I decided to remove that loop for further analysis.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VzsK-OGPhaAi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2.Compute the Laplacian Matrix**\n"
      ],
      "metadata": {
        "id": "pc6C0vOGi48H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute Laplacian (default is combinatorial)\n",
        "gsp_graph_pos.compute_laplacian(lap_type=\"combinatorial\")\n",
        "laplacian = gsp_graph_pos.L\n",
        "\n",
        "print(\"Laplacian Matrix Pos:\")\n",
        "print(laplacian.toarray())  # Display dense matrix for small graphs\n"
      ],
      "metadata": {
        "id": "XVNmcnLVi127"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute Laplacian (default is combinatorial)\n",
        "gsp_graph_neg.compute_laplacian(lap_type=\"combinatorial\")\n",
        "laplacian = gsp_graph_neg.L\n",
        "\n",
        "print(\"Laplacian Matrix Neg:\")\n",
        "print(laplacian.toarray())  # Display dense matrix for small graphs\n"
      ],
      "metadata": {
        "id": "gAvHFzB9jpZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Assign Graph Signal\n",
        "Assign RNa-seq data as the graph signal"
      ],
      "metadata": {
        "id": "L-B1rzLI_5ah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load RNA-seq data\n",
        "rna_seq_data = pd.read_csv(\"/content/drive/MyDrive/Essex_MSc_AI_24-25/MSc_Project_24/Data_to_work_with/GRAND_datasets/MCF7_raw/MCF_RNAseq_countsGSE208731.csv\")  # Replace with your RNA-seq file\n",
        "# Columns: gene, expression\n",
        "\n",
        "# Extract genes from graphs\n",
        "positive_genes = set(G_positive.nodes)\n",
        "negative_genes = set(G_negative.nodes)\n",
        "all_genes_in_graph = positive_genes.union(negative_genes)\n",
        "\n",
        "# Filter RNA-seq data to include only relevant genes\n",
        "filtered_rna_seq_data = rna_seq_data[rna_seq_data['Gene'].isin(all_genes_in_graph)]\n",
        "\n",
        "# Verify the alignment\n",
        "missing_genes = all_genes_in_graph - set(filtered_rna_seq_data['Gene'])\n",
        "if missing_genes:\n",
        "    print(f\"Warning: The following genes are missing in the RNA-seq data: {missing_genes}\")\n",
        "else:\n",
        "    print(\"All graph genes have corresponding RNA-seq data.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "GN6Q05xsZQnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#average the expression data based on experimental coditions\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "# Averaging specific column groups and renaming them\n",
        "column_groups = {\n",
        "    \"MCF7_2D_exp1\": [1, 2, 3],      # Columns 1, 2, 3\n",
        "    \"MCF7_3D_exp1\": [4, 5, 6],      # Columns 4, 5, 6\n",
        "    \"MCF7_2D_exp2\": [7, 8, 9, 10, 11, 12],  # Columns 7 to 12\n",
        "    \"MCF7_3D_exp2\": [13, 14, 15, 16, 17, 18]  # Columns 13 to 18\n",
        "}\n",
        "\n",
        "# Initialize a new DataFrame with the 'gene' column\n",
        "averaged_data = filtered_rna_seq_data[['Gene']].copy()\n",
        "\n",
        "# Compute averages for each group and add to the new DataFrame\n",
        "for new_column, indices in column_groups.items():\n",
        "    averaged_data[new_column] = rna_seq_data.iloc[:, indices].mean(axis=1).round(2)\n",
        "\n",
        "# Save or inspect the resulting DataFrame\n",
        "print(averaged_data.head())\n",
        "averaged_data.to_csv(\"averaged_rna_seq_data.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "GLARvrxc6MTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f6HsRrp6AHya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "import pandas as pd\n",
        "\n",
        "#Load RNA-seq data\n",
        "averaged_rna_seq_data = pd.read_csv(\"/content/drive/MyDrive/Essex_MSc_AI_24-25/MSc_Project_24/Data_to_work_with/GRAND_datasets/averaged_rna_seq_data.csv\")  # Replace with your RNA-seq file\n",
        "\n",
        "\n",
        "\n",
        "# Ensure the RNA-seq data has a 'Gene' column and averaged columns (e.g., MCF7_2D_exp1, etc.)\n",
        "# Create a mapping of genes to expression values for each condition\n",
        "\n",
        "# Extract nodes for G_positive and G_negative\n",
        "positive_genes = set(G_positive.nodes)\n",
        "negative_genes = set(G_negative.nodes)\n",
        "\n",
        "# Filter RNA-seq data for genes in G_positive and G_negative\n",
        "positive_rna_seq = averaged_rna_seq_data[averaged_rna_seq_data['Gene'].isin(positive_genes)]\n",
        "negative_rna_seq = averaged_rna_seq_data[averaged_rna_seq_data['Gene'].isin(negative_genes)]\n",
        "\n",
        "# Create dictionaries for each graph and each condition\n",
        "expression_dicts_positive = {\n",
        "    condition: dict(zip(positive_rna_seq['Gene'], positive_rna_seq[condition]))\n",
        "    for condition in averaged_rna_seq_data.columns[1:]  # Skip 'gene' column\n",
        "}\n",
        "\n",
        "expression_dicts_negative = {\n",
        "    condition: dict(zip(negative_rna_seq['Gene'], negative_rna_seq[condition]))\n",
        "    for condition in averaged_rna_seq_data.columns[1:]  # Skip 'gene' column\n",
        "}\n",
        "\n",
        "# Assign expression values to nodes in G_positive for a specific condition (example: MCF7_2D_exp1)\n",
        "selected_condition = \"MCF7_2D_exp1\"  # Replace with the condition you want to use\n",
        "nx.set_node_attributes(G_positive, expression_dicts_positive[selected_condition], name='expression')\n",
        "nx.set_node_attributes(G_negative, expression_dicts_negative[selected_condition], name='expression')\n",
        "\n",
        "# Verify attributes are set correctly\n",
        "print(\"G_positive node attributes:\")\n",
        "for node, data in G_positive.nodes(data=True):\n",
        "    print(node, data)\n",
        "\n",
        "print(\"\\nG_negative node attributes:\")\n",
        "for node, data in G_negative.nodes(data=True):\n",
        "    print(node, data)\n"
      ],
      "metadata": {
        "id": "YTw4v3zt9nkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pygsp as pg\n",
        "\n",
        "# Step 1: Load or define adjacency matrices\n",
        "# Example: Replace with your actual adjacency matrices\n",
        "A_pos = np.load(\"adjacency_positive.npy\")  # Positive interaction adjacency matrix\n",
        "A_neg = np.load(\"adjacency_negative.npy\")  # Negative interaction adjacency matrix\n",
        "\n",
        "# Step 2: Create graphs using PyGSP\n",
        "graph_pos = pg.graphs.Graph(A_pos)\n",
        "graph_neg = pg.graphs.Graph(A_neg)\n",
        "\n",
        "# Compute Laplacians\n",
        "graph_pos.compute_laplacian('combinatorial')  # Standard Laplacian for positive graph\n",
        "graph_neg.compute_laplacian('combinatorial')  # Standard Laplacian for negative graph\n",
        "\n",
        "# Step 3: Define a graph signal (e.g., gene expression for genes)\n",
        "# Example: Random signals; replace with real gene expression data\n",
        "num_genes = A_pos.shape[1]\n",
        "signal = np.random.rand(num_genes)  # Replace with actual signals for genes\n",
        "\n",
        "# Step 4: Compute signal variation\n",
        "L_pos = graph_pos.L  # Laplacian matrix for positive graph\n",
        "L_neg = graph_neg.L  # Laplacian matrix for negative graph\n",
        "\n",
        "# Signal variation: f^T L f\n",
        "variation_pos = signal.T @ L_pos @ signal\n",
        "variation_neg = signal.T @ L_neg @ signal\n",
        "\n",
        "print(f\"Signal Variation - Positive Graph: {variation_pos}\")\n",
        "print(f\"Signal Variation - Negative Graph: {variation_neg}\")\n",
        "\n",
        "# Step 5: Clustering (optional)\n",
        "# Use spectral decomposition for clustering\n",
        "eigvals_pos, eigvecs_pos = np.linalg.eigh(L_pos)  # Eigenvalues and eigenvectors\n",
        "eigvals_neg, eigvecs_neg = np.linalg.eigh(L_neg)\n",
        "\n",
        "# Example: Clustering using the smallest non-zero eigenvectors\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Number of clusters\n",
        "num_clusters = 3\n",
        "kmeans_pos = KMeans(n_clusters=num_clusters)\n",
        "clusters_pos = kmeans_pos.fit_predict(eigvecs_pos[:, 1:num_clusters+1])  # Positive graph clusters\n",
        "\n",
        "kmeans_neg = KMeans(n_clusters=num_clusters)\n",
        "clusters_neg = kmeans_neg.fit_predict(eigvecs_neg[:, 1:num_clusters+1])  # Negative graph clusters\n",
        "\n",
        "print(f\"Clusters for Positive Graph: {clusters_pos}\")\n",
        "print(f\"Clusters for Negative Graph: {clusters_neg}\")\n"
      ],
      "metadata": {
        "id": "57B2EtxgZaMN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}